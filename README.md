work-absense-forecaster
==============================

![Tests](https://github.com/renegv/work-absense-forecaster/actions/workflows/tests.yml/badge.svg)

A work absense hours ML project

## ðŸ“‘ Table of Contents

- [Setup](#setup)
- [ðŸš€ API Server](#-api-server)
  - [Running with Docker](#running-with-docker-recommended)
  - [API Endpoints](#api-endpoints)
  - [Testing the API](#testing-the-api)
  - [Interactive Documentation](#interactive-documentation)
- [Project Organization](#project-organization)
- [ðŸ§ª Testing Guide](#-testing-guide-for-work-absenteeism-forecaster)
  - [Test Structure](#-test-structure)
  - [Test Coverage](#test-coverage)
  - [Running Tests](#-running-tests)
  - [Continuous Integration](#-continuous-integration)
- [MLflow Integration](#mlflow-integration)

---

## Setup

```
python -m venv env
source env/bin/activate  # On Windows: env\Scripts\activate
pip install -r requirements.txt
```

## MLflow Integration

Run MLFlow server for experiment tracking:

```bash
mlflow server --backend-store-uri sqlite:///my.db --default-artifact-root ./mlruns --host 0.0.0.0 --port 5000
```

The MLflow UI will be available at `http://localhost:5000`

## ðŸš€ API Server

The project includes a FastAPI-based REST API for making absenteeism predictions.

### Running with Docker (Recommended)

**Build and start the API:**
```bash
docker-compose up -d
```

**Stop the API:**
```bash
docker-compose down
```

### API Endpoints

The API will be available at `http://localhost:8000`

- **GET /** - API information and available endpoints
- **GET /health** - Health check endpoint
- **POST /predict** - Make absenteeism predictions
- **GET /docs** - Interactive Swagger UI documentation

### Testing the API

**Health check:**
```bash
curl http://localhost:8000/health
```

**Get API information:**
```bash
curl http://localhost:8000/
```

**Make a prediction:**
```bash
curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d '{
    "reason_for_absence": 23,
    "month_of_absence": 7,
    "day_of_the_week": 3,
    "seasons": 1,
    "transportation_expense": 289,
    "distance_from_residence_to_work": 36,
    "service_time": 13,
    "age": 33,
    "work_load_average/day": 239.554,
    "hit_target": 97,
    "disciplinary_failure": 0,
    "education": 1,
    "son": 2,
    "social_drinker": 1,
    "social_smoker": 0,
    "pet": 1,
    "weight": 90,
    "height": 172
  }'
```

**Expected response:**
```json
{
  "prediction": 1,
  "prediction_label": "High",
  "confidence": 0.7343
}
```

### Interactive Documentation

Once the server is running, access the interactive API documentation:

- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc

These interfaces allow you to:
- View all available endpoints
- See request/response schemas
- Test the API directly from your browser
- Download OpenAPI specification


Project Organization
------------

    â”œâ”€â”€ LICENSE
    â”œâ”€â”€ Makefile           <- Makefile with commands like `make data` or `make train`
    â”œâ”€â”€ README.md          <- The top-level README for developers using this project.
    â”œâ”€â”€ Dockerfile         <- Docker configuration for the API server
    â”œâ”€â”€ docker-compose.yml <- Docker Compose configuration for easy deployment
    â”œâ”€â”€ requirements.txt   <- Full requirements file for development and training
    â”œâ”€â”€ requirements-api.txt <- Minimal requirements for the API server
    â”‚
    â”œâ”€â”€ data
    â”‚   â”œâ”€â”€ external       <- Data from third party sources.
    â”‚   â”œâ”€â”€ interim        <- Intermediate data that has been transformed.
    â”‚   â”œâ”€â”€ processed      <- The final, canonical data sets for modeling.
    â”‚   â””â”€â”€ raw            <- The original, immutable data dump.
    â”‚
    â”œâ”€â”€ docs               <- A default Sphinx project; see sphinx-doc.org for details
    â”‚
    â”œâ”€â”€ models             <- Trained and serialized models, model predictions, or model summaries
    â”‚
    â”œâ”€â”€ notebooks          <- Jupyter notebooks. Naming convention is a number (for ordering),
    â”‚                         the creator's initials, and a short `-` delimited description, e.g.
    â”‚                         `1.0-jqp-initial-data-exploration`.
    â”‚
    â”œâ”€â”€ references         <- Data dictionaries, manuals, and all other explanatory materials.
    â”‚
    â”œâ”€â”€ reports            <- Generated analysis as HTML, PDF, LaTeX, etc.
    â”‚   â””â”€â”€ figures        <- Generated graphics and figures to be used in reporting
    â”‚
    â”œâ”€â”€ setup.py           <- makes project pip installable (pip install -e .) so src can be imported
    â”œâ”€â”€ src                <- Source code for use in this project.
    â”‚   â”œâ”€â”€ __init__.py    <- Makes src a Python module
    â”‚   â”‚
    â”‚   â”œâ”€â”€ api            <- FastAPI REST API for predictions
    â”‚   â”‚   â””â”€â”€ server.py  <- API server implementation
    â”‚   â”‚
    â”‚   â”œâ”€â”€ data           <- Scripts to download or generate data
    â”‚   â”‚   â””â”€â”€ make_dataset.py
    â”‚   â”‚
    â”‚   â”œâ”€â”€ features       <- Scripts to turn raw data into features for modeling
    â”‚   â”‚   â””â”€â”€ build_features.py
    â”‚   â”‚
    â”‚   â”œâ”€â”€ models         <- Scripts to train models and then use trained models to make
    â”‚   â”‚   â”‚                 predictions
    â”‚   â”‚   â”œâ”€â”€ predict_model.py
    â”‚   â”‚   â”œâ”€â”€ train_model.py
    â”‚   â”‚   â””â”€â”€ preprocessors.py
    â”‚   â”‚
    â”‚   â””â”€â”€ visualization  <- Scripts to create exploratory and results oriented visualizations
    â”‚       â””â”€â”€ visualize.py
    â”‚
    â”œâ”€â”€ tests              <- Unit and integration tests
    â”‚   â”œâ”€â”€ unit/          <- Unit tests for individual components
    â”‚   â””â”€â”€ integration/   <- End-to-end integration tests
    â”‚
    â””â”€â”€ tox.ini            <- tox file with settings for running tox; see tox.readthedocs.io


--------

<p><small>Project based on the <a target="_blank" href="https://drivendata.github.io/cookiecutter-data-science/">cookiecutter data science project template</a>. #cookiecutterdatascience</small></p>

## ðŸ§ª Testing Guide for Work Absenteeism Forecaster

### ðŸ“‹ Test Structure

A comprehensive test suite with both **unit tests** and **integration tests** has been created:

```
tests/
â”œâ”€â”€ __init__.py                    # Package initialization
â”œâ”€â”€ conftest.py                    # Shared pytest fixtures (root level)
â”‚
â”œâ”€â”€ unit/                          # Unit tests
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ conftest.py               # Unit-specific fixtures
â”‚   â”œâ”€â”€ test_preprocessors.py     # Tests for custom transformers
â”‚   â”œâ”€â”€ test_train_model.py       # Tests for training pipeline
â”‚   â”œâ”€â”€ test_predict_model.py     # Tests for prediction pipeline
â”‚   â”œâ”€â”€ test_data_utils.py        # Tests for data utilities
â”‚   â””â”€â”€ test_evaluation.py        # Tests for model evaluation
â”‚
â””â”€â”€ integration/                   # Integration tests
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ conftest.py                # Integration-specific fixtures
    â””â”€â”€ test_pipeline_integration.py  # End-to-end pipeline tests

Additional files:
â”œâ”€â”€ pytest.ini                     # Pytest configuration
â”œâ”€â”€ Dockerfile.test                # Docker image for testing
â””â”€â”€ docker-compose.test.yml        # Docker compose for running tests
```

### Test Coverage

#### Unit Tests (`tests/unit/`)

1. **Preprocessors** (`test_preprocessors.py`)
   - `DropColumnsTransformer`: Column dropping functionality
   - `IQRClippingTransformer`: Outlier handling using IQR method
   - `ToStringTransformer`: Type conversion to strings
   - Integration with sklearn pipelines

2. **Model Training** (`test_train_model.py`)
   - Data loading and preparation
   - Pipeline construction
   - Model creation (Logistic Regression, Random Forest, Neural Network)
   - Training and evaluation
   - Multiple model training
   - Model persistence

3. **Model Prediction** (`test_predict_model.py`)
   - Model loading
   - Making predictions on new data
   - Data handling in prediction pipeline

4. **Data Utilities** (`test_data_utils.py`)
   - CSV file loading
   - Column name normalization
   - Data shape validation
   - Data value preservation

5. **Model Evaluation** (`test_evaluation.py`)
   - Metrics calculation (accuracy, F1, recall, precision)
   - Classification reports
   - Confusion matrix creation

#### Integration Tests (`tests/integration/`)

**End-to-End Pipeline** (`test_pipeline_integration.py`)

1. **Complete ML Workflow** (`test_realistic_ml_workflow`)
   - Data loading and preparation
   - Train/test split
   - Preprocessing pipeline creation
   - Model training
   - Model persistence (save/load)
   - Prediction on new data
   - Metrics evaluation
   - Confusion matrix generation
   - File artifact verification

---

### ðŸ”„ Continuous Integration

This project uses GitHub Actions to automatically run tests on every push and pull request.

#### Workflow Overview

The CI pipeline runs:
- **Unit tests** on all test files in `tests/unit/`
- **Integration tests** on all test files in `tests/integration/`
- **Coverage reports** with XML and HTML output
- Tests on Python 3.9

#### Viewing Test Results

1. Navigate to the **Actions** tab in the GitHub repository
2. Click on any workflow run to see detailed test results
3. Coverage reports are uploaded as artifacts (available for 30 days)

#### Workflow Configuration

The workflow is defined in `.github/workflows/tests.yml` and triggers on:
- Pushes to `main` and `develop` branches
- Pull requests to `main` and `develop` branches

---

### ðŸš€ Running tests

#### Build Docker Image

Build the docker image that contains the required environment to run the tests:

```sh
docker build -f Dockerfile.test -t work-absenteeism-test:latest .
```

#### Run All Tests

Run all tests (unit + integration):

```sh
docker-compose -f docker-compose.test.yml run --rm test
```

#### Run Specific Test Suites

Run only unit tests:

```sh
docker-compose -f docker-compose.test.yml run --rm test pytest tests/unit/ -v
```

Run only integration tests:

```sh
docker-compose -f docker-compose.test.yml run --rm test pytest tests/integration/ -v
```

#### Run with Coverage

Run tests with coverage report:

```sh
docker-compose -f docker-compose.test.yml run --rm test-coverage
```

#### Test Markers

Use pytest markers to run specific test categories:

```sh
# Run only unit tests
pytest -m unit

# Run only integration tests  
pytest -m integration

# Run only slow tests
pytest -m slow
```
